# (RAG技術指南-2)RAG 技術：為 AI 模型增添參考資料的能力


# RAG 技術：為 AI 模型增添參考資料的能力

## RAG 是什麼？

在人工智能領域中，RAG（Retrieval-Augmented Generation，檢索增強生成）技術正逐漸成為提升大型語言模型（LLM）表現的關鍵方法。但它究竟是什麼，為何如此重要？讓我們一起深入探討。

### 傳統 LLM 的局限性

在 RAG 技術出現之前，大型語言模型是如何回答問題的呢？

![傳統LLM回答方式](https://imgur.com/uRbbqLF.png)

如上圖所示，傳統的 LLM（如 2023 年訓練的模型）僅能依靠其內部參數中儲存的知識來回答問題。這種方式面臨一個嚴峻的挑戰：**模型內部的知識難以有效更新**。

這個限制引出了 RAG 的核心理念：**讓模型能夠學習參考外部資料，而非僅從內部參數中提取答案**。

### RAG 的運作原理

RAG 技術的理想目標是：**讓 AI 模型能夠隨著世界變化而更新自己的知識庫**。

要實現這一目標，我們需要建立一個完整的系統架構：

![RAG系統架構](https://imgur.com/uHuHqlJ.png)

這個架構中包含兩個關鍵組件：
- **檢索器（Retriever）**：類似於搜尋引擎，負責從資料庫中找出相關文件
- **知識資料庫**：存儲最新、相關的資訊（類似於 ElasticSearch 的功能）

### RAG 命名的含義

RAG（**Retrieval**-Augmented **Generation**）這個名稱本身就揭示了其功能：**檢索增強生成**。

讓我們通過一個具體例子來理解：
1. 一個在 2023 年訓練的 LLM 認為當前美國總統是拜登（因為訓練資料只到 2023 年）
2. 但用戶在 2025 年詢問誰是現任美國總統
3. 使用 RAG 技術後，系統會從資料庫中檢索到 2025 年的最新資訊，顯示現任總統是川普
4. 模型結合用戶問題和檢索到的資訊，正確回答現任總統是川普

## RAG 的優勢與應用場景

RAG 技術不僅能夠更新知識，還能有效減少 AI 的「幻覺」問題（即生成不實資訊），提高回答的準確性。

這是如何實現的呢？關鍵在於提供 LLM **有用的參考文件**。當模型能夠「看著書本回答問題」時，自然能提高準確度。

然而，這也引出了 RAG 系統設計中的核心挑戰：如何選擇合適的檢索器並建立有效的知識庫？這正是本系列文章希望與讀者分享的重點。

## RAG 的基本工作流程

總結來說，RAG 系統的運作流程如下：
1. 接收用戶問題
2. 通過檢索器從資料庫中找出相關文件
3. 將這些文件與原始問題一起提供給 LLM
4. LLM 根據這些資訊生成準確的回答

這種「參考再回答」的方式，正是 RAG 技術的精髓所在。

